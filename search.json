[
  {
    "objectID": "GahlotLi2024SEG/paper.html",
    "href": "GahlotLi2024SEG/paper.html",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "",
    "text": "Digital Twins refer to dynamic virtual replicas of subsurface systems, integrating real-time data and employing advanced generative Artificial Intelligence (genAI) methodologies, such as neural posterior density estimation via simulation-based inference and sequential Bayesian inference. Thanks to combination of these advanced Bayesian inference techniques, our approach is capable of addressing challenges of monitoring and controlling CO2 storage projects. These challenges include dealing with the subsurface’s complexity and heterogeneity (seismic and fluid-flow properties), operations optimization, and risk mitigation, e.g. via injection rate control. Because our Digital Twin is capable of handling diverse monitoring data, consisting of time-lapse seismic and data collected at (monitoring) wells, it entails a technology that serves as a platform to integrate seemingly disparate and siloed fields, e.g. geophysics and reservoir engineering. In addition, recent breakthroughs in genAI, allow Digital Twins to capture uncertainty in a principled way (Yu et al. 2023; Herrmann 2023; Gahlot et al. 2023). By employing training and inference recursively, the Digital Twin trains its neural networks on samples of the simulated current state—i.e., the CO2 saturation/pressure, paired with simulated imaged seismic and/or data collected at (monitoring) wells. These training pairs of the simulated state and simulated observations are obtained by sampling the posterior distribution, \\(\\mathbf{x}_{k-1}\\sim p(\\mathbf{x}_{k-1}\\vert \\mathbf{y}^\\mathrm{o}_{1:k-1})\\), at the previous timestep, \\(k-1\\), conditioned on field data, \\(\\mathbf{y}^\\mathrm{o}_{1:k-1}\\), collected over all previous timesteps, \\(1:k-1\\), followed by advancing the state to the current timestep, followed by simulating (seismic/well) observations associated with that state. Given these simulated state-observation pairs, the Digital Twin’s networks are trained, so they are current and ready to produce samples of the posterior when the new field data comes in—i.e. \\(\\mathbf{x}_{k}\\sim p(\\mathbf{x}_{k}\\vert \\mathbf{y}^\\mathrm{o}_{1:k})\\). While this new neural approach to data assimilation for CO2 storage projects provides what is called an uncertainty-informed Digital Shadow, it lacks decision making and control, which would make it a Digital Twin (Thelen et al. 2022), capable of optimizing storage operations while mitigating risks including the risk of fracturing the cap rock by exceeding the fracture pressure. The latter risk is illustrated in Figure 1, where the first row contains simulated samples of the pressure difference at timestep \\(k=4\\), between the reservoir pressure and hydraulic pressure, without control. These samples for the simulated state exceed the fracture pressure and are denoted by the red areas. During this talk, we will demonstrate how the Digital Twin can make informed decisions to avoid exceeding the fracture pressure.",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "GahlotLi2024SEG/paper.html#introduction",
    "href": "GahlotLi2024SEG/paper.html#introduction",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "",
    "text": "Digital Twins refer to dynamic virtual replicas of subsurface systems, integrating real-time data and employing advanced generative Artificial Intelligence (genAI) methodologies, such as neural posterior density estimation via simulation-based inference and sequential Bayesian inference. Thanks to combination of these advanced Bayesian inference techniques, our approach is capable of addressing challenges of monitoring and controlling CO2 storage projects. These challenges include dealing with the subsurface’s complexity and heterogeneity (seismic and fluid-flow properties), operations optimization, and risk mitigation, e.g. via injection rate control. Because our Digital Twin is capable of handling diverse monitoring data, consisting of time-lapse seismic and data collected at (monitoring) wells, it entails a technology that serves as a platform to integrate seemingly disparate and siloed fields, e.g. geophysics and reservoir engineering. In addition, recent breakthroughs in genAI, allow Digital Twins to capture uncertainty in a principled way (Yu et al. 2023; Herrmann 2023; Gahlot et al. 2023). By employing training and inference recursively, the Digital Twin trains its neural networks on samples of the simulated current state—i.e., the CO2 saturation/pressure, paired with simulated imaged seismic and/or data collected at (monitoring) wells. These training pairs of the simulated state and simulated observations are obtained by sampling the posterior distribution, \\(\\mathbf{x}_{k-1}\\sim p(\\mathbf{x}_{k-1}\\vert \\mathbf{y}^\\mathrm{o}_{1:k-1})\\), at the previous timestep, \\(k-1\\), conditioned on field data, \\(\\mathbf{y}^\\mathrm{o}_{1:k-1}\\), collected over all previous timesteps, \\(1:k-1\\), followed by advancing the state to the current timestep, followed by simulating (seismic/well) observations associated with that state. Given these simulated state-observation pairs, the Digital Twin’s networks are trained, so they are current and ready to produce samples of the posterior when the new field data comes in—i.e. \\(\\mathbf{x}_{k}\\sim p(\\mathbf{x}_{k}\\vert \\mathbf{y}^\\mathrm{o}_{1:k})\\). While this new neural approach to data assimilation for CO2 storage projects provides what is called an uncertainty-informed Digital Shadow, it lacks decision making and control, which would make it a Digital Twin (Thelen et al. 2022), capable of optimizing storage operations while mitigating risks including the risk of fracturing the cap rock by exceeding the fracture pressure. The latter risk is illustrated in Figure 1, where the first row contains simulated samples of the pressure difference at timestep \\(k=4\\), between the reservoir pressure and hydraulic pressure, without control. These samples for the simulated state exceed the fracture pressure and are denoted by the red areas. During this talk, we will demonstrate how the Digital Twin can make informed decisions to avoid exceeding the fracture pressure.",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "GahlotLi2024SEG/paper.html#methodology",
    "href": "GahlotLi2024SEG/paper.html#methodology",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "Methodology",
    "text": "Methodology\nTo make uncertainty informed decisions on adapting the injection rate, 128 samples of the state (see second row Figure 1), \\(\\{\\mathbf{x}^{(m)}_{3}\\}_{m=1}^{128}\\), and permeability, \\(\\{K^{(m)}\\}_{m=1}^{128}\\), are drawn at time-step \\(k=3\\) from the posterior distribution, \\(\\mathbf{x}_{3}\\sim p(\\mathbf{x}_{3}\\vert \\mathbf{y}^\\mathrm{o}_{1:3})\\), for the state conditioned on the observed time-lapse data, and from the distribution for the permeability, \\(K\\sim p(K)\\). To find the optimized injection rate, we first calculate for each sample, \\(K\\) and \\(\\mathbf{x}^{(m)}_{3}\\), the optimized injectivity by \\(\\max_{q_3} q_3\\Delta t \\ \\ \\text{subject to} \\ \\ \\mathbf{x}_{4}['p']&lt;\\mathbf{p}_{\\max}\\) where \\(\\mathbf{p}_{\\max}\\) is the depth-dependent fracture pressure, and \\(\\mathbf{x}_{4}=\\mathcal{M}_3(\\mathbf{x}_{3}, \\mathbf{K}; q_3)\\) the state’s time-advancement denoted by the symbol \\(\\mathcal{M}_3\\). For the fluid-flow simulations, the open-source Julia package JUDI.jl and JutulDarcy.jl are used. Results of these optimizations are included in Figure 2(a), which contains a histogram of the empirical fracture frequency as a function of injection rates at time \\(k=3\\). Given this histogram, our task is to maximize the injection rate given a pre-defined confidence interval (e.g. 95 %), so that the fracture probability remains below a certain percentage e.g. 1%. With these simulations, and the fact that fracture/no-fracture occurrences are distributed according to the Bernoulli distribution, we will demonstrate that we are able to select an injection rate that limits fracture occurrence to the prescribed probability with a prescribed confidence interval. For instance, we can compute \\(Pr([\\mathbf{x}_4['p']&gt;p_{\\max}]&lt;0.01)&lt;1-0.025\\), which corresponds to selecting an injection rate that leads to fracture rate of \\(&lt;1\\%\\) with \\(97.5\\%\\) confidence. The confidence interval is halved, because only conservative (left) injection rates will be selected (see Figure 2(b)).",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "GahlotLi2024SEG/paper.html#results",
    "href": "GahlotLi2024SEG/paper.html#results",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "Results",
    "text": "Results\nTo calculate injection rates that mitigate the risk of exceeding the fracture pressure, we proceed as follows. First, because the optimized injection rates are close to the fracture pressure, we consider these optimization as approximations to the injection rates where the fracture pressure are exceeded. Next, Kernel Density Estimation (KDE) is applied to produce the smooth red curve in Figure 2(a). This smoothed probability function is used to calculate the Cumulative Density Function (CDF), plotted in Figure 2(b). Using the fact that non-fracture/fracture occurrence entails a Bernoulli distribution, confidence intervals can be calculated, \\(\\pm Z_{\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{128}}\\) where \\(\\hat{p}\\) represents the CDF (blue line) and \\(Z_{\\frac{\\alpha}{2}}=1.96\\) with \\(\\alpha=0.05\\). From the CDF and confidence intervals (denoted by the grey areas), the following conclusions can be drawn: First, if the initial injection rate of \\(q_3 = 0.0500 m^3/s\\) is kept, the fracture probability lies between 24.47 – 40.71% (vertical dashed line) and has a maximum likelihood of 32.59%, which are all way too high. Second, if we want to limit the fracture occurrence rate to 1% (red dashed line), then we need to lower the injection rate to \\(q_3=0.0387\\mathrm{m^3/s}\\). To ensure the low fracture occurrence rate of 1%, the reduced injection rate is chosen as the smallest injection rate within the confidence interval. As can be observed from Figure 1 (third row) and Figure 2(b), lowering the injection rate avoids exceeding the fracture pressure at the expense of injecting less CO2. Out of 128 samples, 43 samples are fractured with the initial injection rate, while only one sample is fractured with the controlled injection rate.",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "GahlotLi2024SEG/paper.html#conclusion-and-discussions",
    "href": "GahlotLi2024SEG/paper.html#conclusion-and-discussions",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "Conclusion and discussions",
    "text": "Conclusion and discussions\nThe above example illustrates how Digital Twins can be used to mitigate risks associated with CO2 storage projects. Specifically, we used the Digital Twin’s capability to produce samples of its state (pressure), conditioned on observed seismic and/or well data. Using these samples, in conjunction with samples from the permeability distribution, we were able to capture statistics on the fracture occurrence frequency as a function of the injection rate. Given these statistics, we were in a position to set a fracture frequency and choose the corresponding injection rate as a function of the confidence interval. By following this procedure, exceeding the fracture pressure was avoided by lowering the injection rate. The decision to lower the injection rate, and by which amount, was informed by the Digital Twin, which uses seismic and/or well data to capture reservoir’s state including its uncertainty.\n\n\n\n\n\n\nFigure 1: Pressure state at time-step \\(k=3\\) (second row) and a comparative analysis of pressure outputs (first and third) from the digital twin at time-step \\(k=4\\)\n\n\n\n\n\n\n\n\n\nFigure 2: Injection rate samples and KDE curve(a), CDF curve of fracture probability versus injection rate with 95% confidence interval(b)",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "GahlotLi2024SEG/paper.html#references",
    "href": "GahlotLi2024SEG/paper.html#references",
    "title": "A Digital Twin for Geological Carbon Storage with Controlled Injectivity",
    "section": "References",
    "text": "References\n\n\nGahlot, Abhinav Prakash, Huseyin Tuna Erdinc, Rafael Orozco, Ziyi Yin, and Felix J. Herrmann. 2023. “Inference of CO2 Flow Patterns  a Feasibility Study.” https://doi.org/10.48550/arXiv.2311.00290.\n\n\nHerrmann, Felix J. 2023. “President’s Page: Digital Twins in the Era of Generative AI.” The Leading Edge 42 (11): 730–32.\n\n\nThelen, Adam, Xiaoge Zhang, Olga Fink, Yan Lu, Sayan Ghosh, Byeng D Youn, Michael D Todd, Sankaran Mahadevan, Chao Hu, and Zhen Hu. 2022. “A Comprehensive Review of Digital Twin—Part 1: Modeling and Twinning Enabling Technologies.” Structural and Multidisciplinary Optimization 65 (12): 354.\n\n\nYu, Ting-ying, Abhinav Prakash Gahlot, Rafael Orozco, Ziyi Yin, Mathias Louboutin, and Felix J. Herrmann. 2023. “Monitoring Subsurface CO2 Plumes with Sequential Bayesian Inference.” https://slimgroup.github.io/IMAGE2023/SequentialBayes/abstract.html.\n\n\n\n\n\nFigure 1: Pressure state at time-step \\(k=3\\) (second row) and a comparative analysis of pressure outputs (first and third) from the digital twin at time-step \\(k=4\\)\nFigure 2: Injection rate samples and KDE curve(a), CDF curve of fracture probability versus injection rate with 95% confidence interval(b)",
    "crumbs": [
      "Home",
      "Abstracts",
      "A Digital Twin for Geological Carbon Storage with Controlled Injectivity"
    ]
  },
  {
    "objectID": "Rex2024SEG/paper.html",
    "href": "Rex2024SEG/paper.html",
    "title": "Velocity Continuation for Common Image Gathers with Fourier Neural Operators",
    "section": "",
    "text": "\\[\n    \\newcommand{\\pluseq}{\\mathrel{+}=}\n\\]",
    "crumbs": [
      "Home",
      "Abstracts",
      "Velocity Continuation for Common Image Gathers"
    ]
  },
  {
    "objectID": "Rex2024SEG/paper.html#introduction",
    "href": "Rex2024SEG/paper.html#introduction",
    "title": "Velocity Continuation for Common Image Gathers with Fourier Neural Operators",
    "section": "Introduction",
    "text": "Introduction\nCommon-image gathers (CIGs) are pivotal in migration-velocity analysis (MVA). However, MVA is often hindered by the computational burden of traditional migration methods. To bypass these limitations, we introduce a neural-surrogate learning approach that utilizes Fourier Neural Operators (FNOs, Li et al. 2020) to accelerate MVA. Following the velocity-continuation scheme of Siahkoohi, Louboutin, and Herrmann (2022), we train a survey-specific FNO to map the CIGs associated with one migration-velocity model to another without remigration. This methodology leverages the capacity of FNOs to approximate complex PDE-based mappings, rendering computational cost at inference negligible, thereby expediting MVA. By enabling rapid generation and evaluation of CIGs across various velocity models, it offers a pathway to quickly examine velocity models according to preferred properties and to quantify uncertainties in imaged reflectivities at the same time. Additionally, this methodology paves the way for inverse design optimization, updating velocity models to produce CIGs with desirable characteristics.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Velocity Continuation for Common Image Gathers"
    ]
  },
  {
    "objectID": "Rex2024SEG/paper.html#methodology",
    "href": "Rex2024SEG/paper.html#methodology",
    "title": "Velocity Continuation for Common Image Gathers with Fourier Neural Operators",
    "section": "Methodology",
    "text": "Methodology\nWe conduct a case study on a 2D slice of the Compass model. We generate observed data with 256 sources and 32 ocean bottom nodes, using a Ricker wavelet with central frequency of 0.015 Hz. We assume absorbing boundaries in our study. We add uncorrelated band-limited noise with an SNR of 12 dB for realism. For a given migration-velocity model, CIGs are computed. To train the network to generate CIGs for new migration-velocity models without remigration, 500 new migration-velocity models (Figure 1 (b)) are generated and used to generate CIGs to form our training dataset (Figure 1 (c)). Given these models and CIGs, a FNO is to trained to map \\(a)\\) initial migration-velocity model, \\(b)\\) its CIG, and \\(c)\\) target migration-velocity models, to the CIGs associated with the target migration-velocity models (Figure 1 (d)).\n\n\n\n\n\n\nFigure 1: Our initial velocity model (a) and it’s CIG (b), Set of Smoothed velocity models used as training inputs (c), Migrated CIGs from smoothed velocity models as training targets (d), Surrogate that learns the mapping between initial velocity models, their CIGs, and target models, to produce the corresponding CIGs for the target velocity models (e)\n\n\n\n\n\n\n\n\n\n\nFigure 2: Column 1 represents the target CIG of the smoothed velocity models. Column 2 represents the predicted CIG from our FNO. The last column shows the amplified absolute difference between the first 2 columns",
    "crumbs": [
      "Home",
      "Abstracts",
      "Velocity Continuation for Common Image Gathers"
    ]
  },
  {
    "objectID": "Rex2024SEG/paper.html#results",
    "href": "Rex2024SEG/paper.html#results",
    "title": "Velocity Continuation for Common Image Gathers with Fourier Neural Operators",
    "section": "Results",
    "text": "Results\nFigure 2 displays the FNO prediction in the subsurface-offset domain across various velocity models in an unseen test dataset. Despite some minor errors, the FNO prediction successfully captures the focusing pattern of the CIGs, and correctly produces the imaged reflectivities at the near zero-offsets. Computationally, the upfront training cost could potentially be reduced by transfer learning techniques. At inference, our trained FNO achieves \\(3200\\times\\) speed-up compared to numerical computation of CIGs. These findings substantiate the computational efficiency of the FNOs in generating CIGs for many velocity models, underscoring its applicability in real-time migration-velocity analysis. This framework also presents a way to select good posterior samples of velocity models so that they exhibit desirable properties in their CIGs, making it a good choice of a postprocessor for velocity models produced by generative artificial intelligence workflows (Yin et al. 2023). Additionally, it enables fast uncertainty quantification of imaged reflectivities with respect to many velocity models. In addition to this, the framework could also be pivotal in performing inverse design optimization. By updating our background velocity models such that they yield CIGs with specific, desirable properties, we can further refine our understanding of seismic data. This work is made reproducible at FNO-CIG using distributed Fourier Neural Operators implemented in ParametricOperators.jl.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Velocity Continuation for Common Image Gathers"
    ]
  },
  {
    "objectID": "Rex2024SEG/paper.html#acknowledgement",
    "href": "Rex2024SEG/paper.html#acknowledgement",
    "title": "Velocity Continuation for Common Image Gathers with Fourier Neural Operators",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\nThis research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.\n\nReferences\n\n\nLi, Zongyi, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. 2020. “Fourier Neural Operator for Parametric Partial Differential Equations.”\n\n\nSiahkoohi, Ali, Mathias Louboutin, and Felix J Herrmann. 2022. “Velocity Continuation with Fourier Neural Operators for Accelerated Uncertainty Quantification.” In SEG International Exposition and Annual Meeting, D011S092R004. SEG.\n\n\nYin, Ziyi, Rafael Orozco, Mathias Louboutin, and Felix J. Herrmann. 2023. “WISE: Full-Waveform Variational Inference via Subsurface Extensions.”\n\n\n\n\n\nFigure 1: Our initial velocity model (a) and it’s CIG (b), Set of Smoothed velocity models used as training inputs (c), Migrated CIGs from smoothed velocity models as training targets (d), Surrogate that learns the mapping between initial velocity models, their CIGs, and target models, to produce the corresponding CIGs for the target velocity models (e)\nFigure 2: Column 1 represents the target CIG of the smoothed velocity models. Column 2 represents the predicted CIG from our FNO. The last column shows the amplified absolute difference between the first 2 columns\nFigure 2: Column 1 represents the target CIG of the smoothed velocity models. Column 2 represents the predicted CIG from our FNO. The last column shows the amplified absolute difference between the first 2 columns",
    "crumbs": [
      "Home",
      "Abstracts",
      "Velocity Continuation for Common Image Gathers"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "These abstracts are released under the Creative Commons License type CC BY. 2024 Copyrights (c) SLIM Group, Georgia Institute of Technology.\nAll codes used to produce these results are released under MIT license."
  },
  {
    "objectID": "yin2024SEG/paper.html",
    "href": "yin2024SEG/paper.html",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "",
    "text": "We introduce a cost-effective Bayesian inference method for full-waveform inversion (FWI) to quantify uncertainty in migration-velocity models and its impact on imaging. Our method targets inverse uncertainty due to null-space of the wave modeling operators and observational noise, and forward uncertainty where the uncertainty in velocity models is propagated to uncertainty in amplitude and positioning of imaged reflectivities. This is achieved by integrating generative artificial intelligence (genAI) with physics-informed common-image gathers (CIGs), which greatly reduces reliance on accurate initial FWI-velocity models. In addition, we illustrate the capability of fine-tuning the generative AI networks with frugal physics-based refinements to improve the inference accuracy.",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "yin2024SEG/paper.html#abstract",
    "href": "yin2024SEG/paper.html#abstract",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "",
    "text": "We introduce a cost-effective Bayesian inference method for full-waveform inversion (FWI) to quantify uncertainty in migration-velocity models and its impact on imaging. Our method targets inverse uncertainty due to null-space of the wave modeling operators and observational noise, and forward uncertainty where the uncertainty in velocity models is propagated to uncertainty in amplitude and positioning of imaged reflectivities. This is achieved by integrating generative artificial intelligence (genAI) with physics-informed common-image gathers (CIGs), which greatly reduces reliance on accurate initial FWI-velocity models. In addition, we illustrate the capability of fine-tuning the generative AI networks with frugal physics-based refinements to improve the inference accuracy.",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "yin2024SEG/paper.html#amortized-variational-inference",
    "href": "yin2024SEG/paper.html#amortized-variational-inference",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "Amortized variational inference",
    "text": "Amortized variational inference\nOur method concerns estimation of migration-velocity models from noisy seismic data through the inversion of the wave modeling operator. Instead of seeking only a single velocity model, our method aims to draw samples from the posterior distribution of migration-velocity models conditioned on the observed shot data. In this context, we train conditional normalizing flows (CNFs) to approximate this posterior distribution. To simplify the mapping between seismic image and shot data, we use common-image gathers (CIGs) as an information-preserving physics-informed summary statistic to embed the shot data, and then train the CNFs on pairs of velocity models and CIGs. After training, the inverse of CNF turns random realizations of the standard Gaussian distribution into posterior samples (velocity models) conditioned on any seismic observation that is in the same statistical distribution as the training data, shown in the upper part of the flowchart. We term this amortized inference framework WISE, short for full-Waveform variational Inference via Subsurface Extensions (Yin et al. 2023). We further propose a physics-based Refinement approach to make it WISER.",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "yin2024SEG/paper.html#physics-based-refinement",
    "href": "yin2024SEG/paper.html#physics-based-refinement",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "Physics-based refinement",
    "text": "Physics-based refinement\nWhile the trained amortized CNF can generate posterior velocity samples instantaneously at inference, the accuracy of CNFs might be deteriorated due to out-of-distribution issues — i.e., the observed data is generated by an out-of-distribution velocity model, or through a slightly different forward modeling operator (e.g. acoustic-elastic, differing source function, attenuation effect, unremoved shear wave energy, etc). To meet this challenge and bridge the so-called amortization gap, we apply a physics-based refinement approach to fine-tune the trained network. We compose a shallower invertible network with the trained CNFs, where the shallower network is initialized with random weights and acts on the latent space. Following a transfer learning scheme, we freeze the weights of the trained CNF and only update the weights of the shallower network in order for the posterior samples to fit the observed shot data. This process is shown in the lower part of the flowchart in red color.",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "yin2024SEG/paper.html#downstream-imaging",
    "href": "yin2024SEG/paper.html#downstream-imaging",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "Downstream imaging",
    "text": "Downstream imaging\nTo understand how the uncertainty in the migration-velocity models propagates to imaged reflectors, forward uncertainty is assessed by carrying out high-frequency imaging for different posterior velocity samples, shown on the right-hand side of the flowchart. The uncertainty in the imaged reflectors is revealed in variance in both the amplitude and the positioning of the reflectors.\n\n\n\n\n\n\nFigure 1: WISER workflow.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n\n\n\n\n(f)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g)\n\n\n\n\n\n\n\n\n\n\n\n(h)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(i)\n\n\n\n\n\n\n\n\n\n\n\n(j)\n\n\n\n\n\n\n\nFigure 2: (a) 1D initial FWI-velocity model used for CIG computation; (b) unseen ground truth velocity model; (c) estimated migration-velocity models from WISE; (e) point-wise standard deviation of the migration-velocity models from WISE; (g) imaged reflectivities using migration-velocity models from WISE; (i) point-wise standard deviation of the imaged reflectivities from WISE; (d)(f)(h)(j) are the counterparts of (c)(e)(g)(i) but from WISER.",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "yin2024SEG/paper.html#references",
    "href": "yin2024SEG/paper.html#references",
    "title": "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements",
    "section": "References",
    "text": "References\n\n\nYin, Ziyi, Rafael Orozco, Mathias Louboutin, and Felix J Herrmann. 2023. “WISE: Full-Waveform Variational Inference via Subsurface Extensions.” arXiv Preprint arXiv:2401.06230.\n\n\n\n\n\nFigure 1: WISER workflow.\nFigure 2 (a): \nFigure 2 (b): \nFigure 2 (c): \nFigure 2 (d): \nFigure 2 (e): \nFigure 2 (f): \nFigure 2 (g): \nFigure 2 (h): \nFigure 2 (i): \nFigure 2 (j):",
    "crumbs": [
      "Home",
      "Abstracts",
      "WISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html",
    "href": "erdinc2024SEG/abstract.html",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "",
    "text": "\\[\n    \\newcommand{\\pluseq}{\\mathrel{+}=}\n\\]",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#abstract",
    "href": "erdinc2024SEG/abstract.html#abstract",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Abstract",
    "text": "Abstract\nDiffusion generative models are powerful frameworks for learning high-dimensional distributions and synthesizing high-fidelity images. However, their efficacy in training predominantly hinges on the availability of complete, high-quality training datasets, a condition that often proves unattainable, particularly in the domain of subsurface velocity-model generation. In this work, we propose to synthesize proxy subsurface velocities from incomplete well and imaged seismic observations by introducing additional corruptions to the observations during the training phase. In this context, proxy velocity models refer to random realizations of subsurface velocities that are close in distribution to the actual subsurface velocities. These proxy models can be used as priors to train neural networks with simulation-based inference. Our approach facilitates the generation of these proxy velocity samples by utilizing available datasets composed merely of seismic images and 5 (for now) wells per seismic image.After training, our foundation generative model permits the generation of velocity samples derived from unseen RTMs without the need of having access to wells.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#methodology",
    "href": "erdinc2024SEG/abstract.html#methodology",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Methodology",
    "text": "Methodology\nSeismic velocity-model synthesis from incomplete measurements with Generative Geostatistical Modeling (GGM) is an ill-posed problem. In addition, acquiring comprehensive realistic velocity-model training datasets from seismic shot data through the process of full-waveform inversion proves to be too costly. Generative models, particularly diffusion models, offer a solution by training conditional neural networks to synthesize plausible samples, that we refer to as proxy models. After training, these proxy models are synthesized through an iterative denoising process, facilitating high-fidelity, high-dimensional sample generation. Our work leverages generative diffusion models by producing proxy velocity models from limited well-log and imaged seismic information. It negates the need of having access to fully-sampled velocity models during training. Well data provides the only incomplete access to the ground-truth velocities.\nUnfortunately, this lack of fully-sampled velocity models precludes the use of traditional neural reconstruction methods that rely on having access to fully-sampled training examples (Wang, Huang, and Alkhalifah 2024). Inspired by recent work by Giannis Daras and Klivans (2023), Orozco, Louboutin, and Herrmann (2023) and Peters (2020), our study adopts an alternative approach that only requires access to sub-sampled velocity models (i.e. well-log data, denoted by the sub-sampling operator \\(\\mathbf{A}\\)). The sub-sampling corresponds to the action of binary masks with unity columns at locations where well-log data is available. The reconstruction of the fully-sampled proxy velocity models is conditioned on seismic images (denoted by \\(\\mathbf{c}\\)). The proposed training process is illustrated in Figure 1 and repeatedly involves: selection of a 2D seismic image, \\(\\mathbf{c}\\), paired with 5 well logs \\(\\mathbf{y}\\) from which the sub-sampling masks, \\(\\mathbf{A}\\) are generated. Conditioned on this sub-sampling mask, a more sub-sampled mask, \\(\\mathbf{\\widetilde{A}}\\) (cf. the masks \\(\\mathbf{A}\\) and \\(\\mathbf{\\widetilde{A}}\\) in Figure 1) is generated by zeroing out more columns. Given the action of the more sub-sampled mask on noised and scaled complete well-log data, the neural network is trained to denoise and fit the complete well-log data conditioned on the seismic image. Our network is trained by repeating this process over 20,000 denoising iterations on 2 A100 GPUs involving a training dataset of 3000 training samples.\n\n\n\n\n\n\nFigure 1: Training-loss formulation: field observations (RTMs and wells) along with column-wise masks (\\(\\mathbf{A}\\)) are sampled initially. Conditioned on these masks, further sub-sampling masks (\\(\\mathbf{\\widetilde{A}}\\)) are generated. The neural denoising model \\(h_\\theta\\), informed by the sub-sampling masks, noisy sub-sampled well information and RTMs, is trained to reconstruct the complete, noise-free velocity model.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#results",
    "href": "erdinc2024SEG/abstract.html#results",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Results",
    "text": "Results\nFigure 2 presents results of our generative model for two unseen examples of imaged reflectivities. Given these unseen seismic images (RTMs), our trained neural model synthesizes subsurface velocity models without relying on well data. To validate the quality of our generative samples, comparisons are made between the posterior means (the average of 200 generative samples) and their respective unseen ground-truth test velocity models. These velocity models remained entirely unseen during the training and generative phase. We observe that the posterior means can capture long range structures and produce visually meaningful velocity samples, evidenced by the high Structural Similarity Index (SSIM) scores of 0.88 and 0.91. Furthermore, the conditional posterior variances align closely with particular structures within the velocity models, which underscores the generative model’s capacity to accurately reflect the uncertainty due to two factors: the variability in the subsurface prior information captured from wells seen during training and the uncertainty due to the RTM imaging process. From these results, we conclude that our method conditioned on imaged seismic data is capable of producing high-fidelity samples from the underlying distribution for subsurface velocity models. These samples will serve as input to our full-Waveform variational Inference via Subsurface Extensions (WISE) framework (Yin et al. 2023). Looking ahead, future directions include expanding our dataset across varied geological settings, inclusion of prompts to guide the sample generation, all geared towards advancing on the road to a seismic-based foundation model for subsurface velocities.\n\n\n\n\n\n\nFigure 2: The denoising generative model is tested on two previously unseen seismic images. For each case, we fed the corresponding RTM into the network and generated velocity samples (200 samples for each example). Subsequently, we computed both the posterior mean and variance. To assess the accuracy of our model, we included the SSIM between the ground-truth to the posterior means",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#significance",
    "href": "erdinc2024SEG/abstract.html#significance",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Significance",
    "text": "Significance\nWe utilized generative diffusion models to synthesize realistic subsurface velocity model samples. Unlike prior approaches dependent on fully sampled velocity model datasets, our method achieves training with merely \\(\\approx 2\\)% of velocity information derived from well data and corresponding Reverse Time Migrations (RTMs). After training is completed, our model’s sampling mechanism operates without well data, conditioned solely on RTMs to generate velocity samples. The velocity samples produced by our technique are highly beneficial for subsequent tasks such as WISE, which rely on having access to high-fidelity samples of the distribution of subsurface velocity models. Additional material is available at https://slimgroup.github.io/IMAGE2024/.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#references",
    "href": "erdinc2024SEG/abstract.html#references",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "References",
    "text": "References\n\n\n\nFigure 1: Training-loss formulation: field observations (RTMs and wells) along with column-wise masks (\\(\\mathbf{A}\\)) are sampled initially. Conditioned on these masks, further sub-sampling masks (\\(\\mathbf{\\widetilde{A}}\\)) are generated. The neural denoising model \\(h_\\theta\\), informed by the sub-sampling masks, noisy sub-sampled well information and RTMs, is trained to reconstruct the complete, noise-free velocity model.\nFigure 2: The denoising generative model is tested on two previously unseen seismic images. For each case, we fed the corresponding RTM into the network and generated velocity samples (200 samples for each example). Subsequently, we computed both the posterior mean and variance. To assess the accuracy of our model, we included the SSIM between the ground-truth to the posterior means",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#acknowledgement",
    "href": "erdinc2024SEG/abstract.html#acknowledgement",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\nThis research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "erdinc2024SEG/abstract.html#software-availability",
    "href": "erdinc2024SEG/abstract.html#software-availability",
    "title": "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations",
    "section": "Software availability",
    "text": "Software availability",
    "crumbs": [
      "Home",
      "Abstracts",
      "Building subsurface velocity priors from field observations"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Image2024",
    "section": "",
    "text": "This is a Quarto website.\nAll submissions to the Image24 conference with additional figures, references, …\nList of abstracts:\n\nVelGen: Building subsurface velocity priors from field observations\nVelocity Continuation for Common Image Gathers with Fourier Neural Operators A framework to accelerate migration-velocity analysis and uncertainty quantification\nDigital twin with control A Digital Twin for Geological Carbon Storage with Controlled Injectivity\nWISER: full-Waveform variational Inference via Subsurface Extensions with Refinements"
  }
]