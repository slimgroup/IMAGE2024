---
title: "Generative Geostatistical Modeling from Incomplete Well and Imaged Seismic Observations"

author:
  - name: Huseyin Tuna Erdinc
    orcid: "0009-0006-0752-7202"
    email: herdinc3@gatech.edu
    affiliations:
    - name: Georgia Institute of Technology
  - name: Rafael Orozco
    affiliations:
      name: Georgia Institute of Technology
  - name: Felix J. Herrmann
    orcid: "0000-0003-1180-2167"
    affiliations:
      - name: Georgia Institute of Technology
        url: https://slim.gatech.edu/
affiliations:
  - id: gatech
    name: Georgia Institute of Technology
    url: https://slim.gatech.edu/
description: | 
  Creating velocity from field observations.
bibliography: abstract.bib
abstract: |
  Creating velocity from field observations, reproducible at []()
---

::: hidden
$$
    \newcommand{\pluseq}{\mathrel{+}=}
$$
:::

## Abstract

Diffusion generative models are emerging powerful frameworks for learning high-dimensional distributions and synthesizing high-fidelity images. However, their efficacy in training predominantly hinges on the availability of complete, high-quality training datasets, a condition that often proves unattainable, particularly in the domain of subsurface velocity-model generation. In this work, we propose to synthesize proxy subsurface velocities from incomplete well and imaged seismic observations by introducing additional observation distortions during the training phase. In this context, proxy velocity models refer to random realizations of subsurface velocities that are close in distribution to the actual subsurface velocities. These proxy models are used to train neural networks with simulation-based inference, which relies on having access to these samples. Our approach facilitates the generation of these proxy velocity samples by utilizing available datasets composed merely of seismic images and 5 (for now) wells per seismic image. After training, our foundation neural model permits the generation of velocity samples derived from novel RTMs without the need of having access to wells.

## Methodology

Seismic velocity-model synthesis from incomplete measurements with Generative Geostatistical Modeling (GGM) is an ill-posed problem. In addition, acquiring comprehensive realistic velocity-model training datasets from seismic shot data through the process of full-waveform inversion proves to be too costly and unrealistic. Generative models, particularly diffusion models, offer a solution by training conditional neural networks to synthesize plausible samples, which we refer to as proxy models. After training, these proxy models are synthesized through a iterative denoising process, facilitating high-fidelity high-dimensional sample generation. Our work leverages generative diffusion models by producing proxy velocity models from limited well-log and imaged seismic information. It negates the need of having access to fully-sampled velocity models during training. Well data provides the only incomplete access to the ground-truth velocities.

Unfortunately, this lack of fully-sampled velocity models precludes the use of traditional neural reconstruction methods that rely on having access to both sub- and fully-sampled training pairs [@wang2024controllable]. Inspired by recent work by @ambient, @rafaelkriging and @basdeep, our study adopts an alternative approach that relies on having access to distorted (incomplete well-log data, denoted by the sampling operator $\mathbf{A}$), and artificially even more distorted (denoted by sampling operator $\mathbf{\widetilde{A}}$) well-log data. These distortions correspond to the action of binary masks with unity non-zero columns at locations where well-log data is available. The reconstruction of the fully-sampled proxy velocity models is conditioned on seismic images (denoted by the symbol $\mathbf{c}$). The proposed training concept is illustrated in @fig-sup and repeatedly involves: selection of a 2D seismic image, $\mathbf{c}$, intercepted by 5 well logs from which the distorted sampling mask, $\mathbf{A}$, the distorted well data, $\mathbf{y}$, are generated. Conditioned on this sampling mask, an artificially more distorted mask, $\mathbf{\widetilde{A}}$ (cf. the masks $\mathbf{A}$ and $\mathbf{\widetilde{A}}$ in @fig-sup) is generated. Given the action of the artificially-distorted mask on artificially noised and scaled complete well-log data, the neural network is trained to fit the complete well-log data conditioned on the seismic image. Our network is trained by repeating this process over 20,000 iterations on 2 A100 GPUs involving a training dataset of 6000 training samples.

::: {#fig-sup}
![](figures/IMAGE2024_figure1_new.png)

Training-loss formulation: field observations (RTMs and wells) along with column-wise masks ($\mathbf{A}$) are sampled initially. Conditioned on these masks, artificial distortion masks ($\mathbf{\widetilde{A}}$) are generated. The neural denoising model $h_\theta$, informed by the distortion masks, noisy distorted well information and RTMs, is trained to reconstruct the complete, noise-free velocity model.
:::

## Results

@fig-unsup presents results of our generative model for two distinct unseen examples for the imaged reflectivity. Given these unseen seismic images (RTMs), our trained neural model synthesizes subsurface velocity models without relying on well data. To validate the quality of our generative samples, comparisons are made between the posterior means (the average of 200 samples conditioned in the two RTMs) and unseen ground-truth test velocity models. These velocity models remained entirely unseen during the training and generative phase. From these comparisons, we observe that the posterior means can capture long range structures and produce visually meaningful velocity samples, evidenced by the Structural Similarity Index (SSIM) scores of 0.88 and 0.91. Furthermore, the conditional posterior variances align closely with particular structures within the velocity models, which underscores the generative model's capacity to accurately reflect underlying geological heterogeneity. From these results, we conclude that our method conditioned on imaged seismic data is capable of producing high-fidelity samples from the underlying distribution for subsurface velocity models. These samples will serve as input to our full-Waveform variational Inference via Subsurface Extensions (WISE) framework [@yin2023wise]. Looking ahead, future directions include expanding our dataset across varied geological settings, inclusion of prompts to guide the sample generation, all geared towards advancing on the road to a seismic-based foundation model for subsurface velocities.

::: {#fig-unsup}
![](figures/IMAGE2024_figure2_new.png)

The denoising generative model is tested on two distinct, previously unseen seismic images. For each case, we fed the corresponding RTM into the network and generated velocity samples (200 samples for each example). Subsequently, we computed both the posterior mean and variance. To assess the accuracy of our model, we included the SSIM score comparing the ground-truth to the calculated posterior means.
:::
 

## Significance

We utilized generative diffusion models to synthesize realistic subsurface velocity model samples. Unlike prior approaches dependent on fully sampled velocity model datasets, our method achieves training with merely $\approx 2$% of velocity information derived from well data and corresponding Reverse Time Migrations (RTMs). After training is completed, our model's sampling mechanism operates without well data, conditioned solely on RTMs to generate velocity samples. The velocity samples produced by our technique are highly beneficial for subsequent tasks such as WISE, which rely on having access to high-fidelity samples of the distribution of subsurface velocity models. Additional material is available at https://slimgroup.github.io/IMAGE2024/.


## Acknowledgement {.appendix}

This research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.


## Software availability {.appendix}

## References
