---
title: "Domain transfer on  Shot records"
author:
  - name: Yadhu Kartha
    email: yadhukartha@gatech.edu
    affiliations:
      - ref: gatech
  - name: Abhinav Gahlot
    affiliations:
      - ref: gatech 
  - name: Huseyin Tuna Erdinc
    affiliations:
      - ref: gatech       
  - name: Mathias Louboutin
    orcid: "0000-0002-1255-2107"
    email: mlouboutin3@gatech.edu
    url: https://mloubout.github.io
    affiliations: Devito Codes Ltd
  - name: Felix J. Herrmann
    orcid: "0000-0003-1180-2167"
    affiliations:
      - ref: gatech
affiliations:
  - id: gatech
    name: Georgia Institute of Technology
    url: https://slim.gatech.edu/
description: | 
  Domain transfer using Condtional normalizing flows on Shot records.
bibliography: paper.bib
abstract: |
  code reproducible at [here](https://github.com/YadhuKartha686/Domain_transfer/blob/main/scripts/DTwithCNF.jl)
---

::: hidden
$$
    \newcommand{\pluseq}{\mathrel{+}=}
$$
:::

## Motivation

The primary objective is to develop a mapping from acoustic shot records without density information to acoustic shot records with density information. One approach involves generating shot records with density information directly, thereby achieving stronger reflections and a clearer image of the subsurface. This extra parameter of density makes it  computationally expensive. We used generative AI to solve this problem. Recently, generative AI has significantly impacted the field of accurate image generation. We opted for Conditional Normalizing Flows due to its invertibility and computationally efficient characteristics. This method promises to provide an accurate and cost-effective way to generate acoustic shot records with density information from those without it, which are typically expensive to create. With generative AI, the time required for sampling is almost instantaneous (~10 ms) compared to using traditional computational software to produce shot records.

## Method

This methodology employs machine learning techniques to establish a bidirectional mapping between two domains: acoustic shot records with and without density. This approach allows for a detailed analysis and comparison between these two states. Acoustic shot records with density have stronger reflections and sharper events compared to those without density information. This makes shot records with density expensive to generate. Conditional normalizing flows are generative networks that take complex image distributions and transform them into Gaussian noise. Since this process is fully invertible, sampling Gaussian noise can, in turn, produce posterior samples during the inverse pass through these networks. 

Data for the training phase were generated by selecting slices from the Compass model and positioning sources and receivers at the ocean bottom to replicate real life scenario. The chosen source frequency was 25 Hz. Receivers were placed along the top of the model at one-meter intervals. The recording time is 1800 ms, and the width of the model is approximately 625 meters. I used JUDI [@witteJUDI2019] package in Julia as a simulation software. A total of 2000 slices of acoustic shot records, both with and without density, were used as training data.

In the training phase, we employ an alternating methodology with GANs to train both the discriminator and the generator. This method involves initially training the discriminator to distinguish between real and generated data, followed by training the generator to create data that the discriminator cannot easily classify as generated. A key innovation in our approach is the adoption of a Conditional Normalizing Flow [@orozco2023invertiblenetworksjl] network as the generator, while the discriminator features a 5-block convolution layer classifier and fully connected dense layer with sigmoid activation to act as a binary classifier. The core principle of this training method is that the generator aims to produce images that deceive the discriminator, which in turn learns to differentiate the generated images from real ones. This approach is motivated by its computational efficiency and the advantage of invertibility, an aspect that conventional GANs lack. Unlike traditional GANs, which require separate networks for each direction of data transfer, a single conditional normalizing flow network suffices for bidirectional transfer. The networks are trained using adversarial loss [@Dreher_2023]. The input to the network includes shot records and their conditions, represented as arrays of zeros and ones to effectively label the domains. 

Figure 1 describes the training procedure and the loss term used to jointly optimize these networks. The loss term is a min-max objective designed to help the generator produce higher-quality images and enable the discriminator to differentiate more effectively. During generation, a shot record is passed through the network along with its domain indication, prompting the network to transfer it to the alternate domain. This method surpasses previous approaches that required two separate GAN networks for bidirectional domain mapping in terms of computational costs, thereby enhancing memory efficiency with the use of a single conditional normalizing flow network. [@10.1190/geo2022-0247.1]  

::: {#fig-vdtov }
![](figures/trainingreg.png)

Figure 1 contains a schematic diagram of the training regime. The blue arrows indicate forward pass through the conditional normalizing flow (G) and the green arrows indicate the inverse or generation pass. Discriminator (D) and conditional normalizing flow (G) are trained as per the loss term described here.  Here X represent the shot record image, Y represent the condition, that is the domain the shot record belongs which are domain 1 and domain 2 and Z represents the latent space. Domain 1 and Domain 2 are arrays of integers 1 and 0 in the same shape as the input image. Here, it's observed that the latent space in the forward pass is utilized for domain transfer, effectively moving the input image into a different domain.
:::


## Results

We apply the proposed domain transfer approach both ways (velocity-only ⇆ velocity+density) to previously unseen shot records. The results from the learned network on these test shot records are presented in Figures 2 and 3, respectively. For reference, the original shot data are included on the left, followed by the domain transferred shot record on the right. Figure 2 shows that the domain transferred (velocity+density → velocity-only) shot record has dimmer reflection events as expected of a velocity-only shot record. The red circles indicate large changes between the shot records. Alternatively, figure 3 shows that the domain transferred (velocity-only → velocity+density) shot record has brighter and sharper reflection events compared to the test shot record, which is expected for a velocity+density shot record. We see these changes in the regions denoted by red circles.

::: {#fig-vdtov }
![](figures/comparetestveldenandvel.png)

Test shot record data versus domain-transferred shot record. The left column consists of the test shot record, which includes both velocity and density which is the input to the network, while the right column displays the domain-transferred shot record predicted by the network, where this test shot record has been converted to only the velocity domain.

:::

::: {#fig-vtovd }
![](figures/comparetestvelandvelden.png)

Test shot record data versus domain-transferred shot record. The left column shows the test shot record, which includes velocity which is the input to the network, while the right column displays the domain-transferred shot record predicted by the network, where this test shot record has been converted to include both velocity and density domains.

:::


## Significance

Conditional Normalizing Flow networks bring notable improvements in computational efficiency and speed up image generation. This approach proves its adaptability by enabling bidirectional mapping between two related yet distinct domains, where one may be challenging or costly to obtain and the other more accessible. An important application for the extension of this work involves mapping between acoustic and elastic shot records. Future works include using this method on more complex datasets.

### References

::: {#refs}
:::

## Acknowledgement {.appendix}

This research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.

