---
title: "Domain transfer on  Shot records"
author:
  - name: Yadhu Kartha
    email: yadhukartha@gatech.edu
    url: https://mloubout.github.io
    affiliations:
      - ref: gatech
  - name: Felix J. Herrmann
    orcid: "0000-0003-1180-2167"
    affiliations:
      - ref: gatech
affiliations:
  - id: gatech
    name: Georgia Institute of Technology
    url: https://slim.gatech.edu/
description: | 
  Domain transfer using Condtional normalizing flows on Shot records.
bibliography: paper.bib
abstract: |
  code reproducible at [here](https://github.com/YadhuKartha686/Domain_transfer/blob/main/scripts/DTwithCNF.jl)
---

::: hidden
$$
    \newcommand{\pluseq}{\mathrel{+}=}
$$
:::

## Motivation

The primary objective is to develop a mapping from acoustic shot records without density information to those with density information but this is a computationally expensive process. There is a pressing need for a computationally efficient approach to generate shot records with density information from those lacking it, in order to achieve stronger reflections and a clearer image of the subsurface. We approached this problem using the method of GenAI. Recently, GenAI has made quite an impact in accurate image generation, and using these techniques provides a computationally effective method to generate images. This method promises to offer an accurate and cost-effective way to produce acoustic shot records with density information from shot records without density information; the former are typically expensive to create. Using GenAI, the sampling time is almost 10 times less than when using computational software to produce shot records.

## Method

This methodology employs machine learning techniques to establish a bidirectional mapping between two domains: acoustic shot records with and without density. This approach allows for a detailed analysis and comparison between these two states. Acoustic shot records with density have stronger reflections and sharper events compared to those without density information. This makes shot records with density expensive to generate. Conditional normalizing flows are generative networks that take complex image distributions and transform them into Gaussian noise. Since this process is fully invertible, sampling Gaussian noise can, in turn, produce posterior samples during the inverse pass through these networks. 

Data for the training phase were generated by selecting slices from the BGCompass model and positioning sources and receivers at the top. The chosen source frequency was 25 Hz. Specifically, the shot record produced by the central source was selected for the dataset. Receivers were placed along the top of the model at one-meter intervals. The recording time is 1800 ms, and the width of the model is approximately 625 meters. A total of 2000 slices of acoustic shot records, both with and without density, were used as training data.

In the training phase, we employ an alternating methodology with GANs to train both the discriminator and the generator. This method involves initially training the discriminator to distinguish between real and generated data, followed by training the generator to create data that the discriminator cannot easily classify as generated. A key innovation in our approach is the adoption of a Conditional Normalizing Flow network as the generator, while the discriminator features a 5-block convolution layer classifier. The core principle of this training method is that the generator aims to produce images that deceive the discriminator, which in turn learns to differentiate the generated images from real ones. This approach is motivated by its computational efficiency and the significant advantage of invertibility, an aspect that conventional GANs lack. Unlike traditional GANs, which require separate networks for each direction of data transfer, a single conditional normalizing flow network suffices for bidirectional transfer. The networks are trained using adversarial loss[@Dreher_2023], with the generator undergoing validation at each epoch. The input to the network includes shot records and their conditions, represented as arrays of zeros and ones to effectively label the domains. 

Figure 1 describes the training procedure and the loss term used to jointly optimize these networks. The loss term is a min-max objective designed to help the generator produce higher-quality images and enable the discriminator to differentiate more effectively. During generation, a shot record is passed through the network along with its domain indication, prompting the network to transfer it to the alternate domain. This method surpasses previous approaches that required two separate GAN networks for bidirectional domain mapping, thereby enhancing memory efficiency with the use of a single conditional normalizing flow network.[@10.1190/geo2022-0247.1]  

::: {#fig-vdtov }
![](figures/trainingreg.png)

Figure 1 contains a schematic diagram of the training regime. The blue arrows indicate forward pass through the conditional normalizing flow (G) and the green arrows indicate the inverse or generation pass. Discriminator (D) and conditional normalziing flow (G) are trained as per the loss term described here.  Here X represent the shot record image, Y represent the condition, that is the domain the shot record belongs which are domain 1 and domain 2 and Z represents the latent space. Domain 1 and Domain 2 are arrays of integers 1 and 0 in the same shape as the input image. Here, it's observed that the latent space in the forward pass is utilized for domain transfer, effectively moving the input image into a different domain.
:::


## Results

We apply the proposed domain transfer approach to a previously unseen shot record. Results for the learned network on these test shot record are presented in Figures 1 and 2, respectively. For reference, the original shot data are included on the left, followed by the domain transferred shot record on the right. Figure 1 shows that the domain transferred shot record has dimmer events in the body and the waves are sligtly thinner as expected of a velocity only shot record. Figure 2 shows that the domain transferred shot record has brighter and sharper events compared to the test shot record, which is expected from the shot record which consists of velocity and density due to strong relfections.


::: {#fig-vdtov }
![](figures/comparetestveldenandvel.png)

Test shot record data vs domain transferred shot record. Left columnn consists of test shot record consisting of velocity and density and right column consists of domain transferred shot record of this test shot record to only velocity domain. The red circle indicate large changes visible by the naked eye. We can see that the domain transferred shot record has dimmer events and weaker reflections.
:::

::: {#fig-vtovd }
![](figures/comparetestvelandvelden.png)

Test shot record data vs domain transferred shot record. Left columnn consists of test shot record consisting of velocity and right column consists of domain transferred shot record of this test shot record to velocity and density domain.The red circle indicate large changes visible by the naked eye. We can see that the domain transferred shot record has brighter events and stringer reflections.
:::

::: {#fig-test }
![](figures/testdatacomp.png)

Test shot record of one domain vs test shot record of second domain. Left column represents test shot record of velcity only shot record and right column consists of velocity and density shot record.The red circle indicate large changes visible by the naked eye. We can see that the left column shot record has brighter events and stringer reflections.
::: 


## Significance

Conditional Normalizing Flow networks bring notable improvements in computational efficiency and speed up image generation, outperforming other cutting-edge networks. This approach proves its adaptability by enabling bidirectional mapping between two related yet distinct domains, where one may be challenging or costly to obtain and the other more accessible. An outstanding application is converting between acoustic and elastic shot records. Looking forward, there's potential to employ this technique for style transfer in complex datasets, paving the way for innovative research and applications.

### References

::: {#refs}
:::

## Acknowledgement {.appendix}

This research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.

