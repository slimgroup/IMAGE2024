[
  {
    "objectID": "Yunlin2024SEG/image2024.html",
    "href": "Yunlin2024SEG/image2024.html",
    "title": "Enhancing Full-Waveform Variational Inference through Stochastic Resampling and Data Augmentation",
    "section": "",
    "text": "Introduction: Full Waveform Inversion (FWI) is a computationally expensive iterative optimization scheme that determines migration-velocity models by minimizing the discrepancy between observed seismic shot data and data generated by a forward model parameterized by the velocity. Recent advancements, such as full-Waveform variational Inference via Subsurface Extensions (WISE), produce amortized neural posterior estimates that enable fast online inference. These neural approximations to the posterior distribution, \\(p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\vert\\mathbf{y})\\approx p(\\mathbf{x}\\vert\\mathbf{y})\\) with \\(\\mathbf{x}\\), the velocity model, \\(\\mathbf{x}\\), the shot data, and \\(\\boldsymbol{\\theta}\\), the network weights, are obtained with variational inference, which requires extensive off-line training. Aside from providing statistically robust estimates via the conditional mean, \\(\\mathbb{E}_\\mathbf{x}(p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\vert\\mathbf{y}))\\) these neural posterior also provide a useful metric of the uncertainty in terms of the variance \\(\\mathbb{V}_\\mathbf{x}(p_{\\boldsymbol{\\theta}}(\\mathbf{x}\\vert\\mathbf{y}))\\). To make this approach computationally feasible, we follow Yin et al. (2023) and train on pairs \\(\\{(\\mathbf{x}^{(m)}, \\mathbf{\\bar{y}}^{(m)})\\}_{m=1}^M\\), where the \\(\\mathbf{\\bar{y}}^{(m)}\\) stand for subsurface-offset Common Image Gathers, computed from each shot dataset, \\(\\mathbf{y}^{(m)}\\). While CIG’s as physics-based summary statistics are better suited to inform the posterior than plane migration—i.e, they preserve information even when the migration-velocity model is poor, their performance still depends on the the choice of the initial migration-velocity model, \\(\\mathbf{x}_0\\). In During this talk, we will study the impact of varying initial background velocity models on the quality of the amortized neural posterior sampler. We will also investigate how augmenting the training set with different initial background velocity models can lead to improved performance.\nMethod: By interpreting the initial migration-velocity model as a stochastic latent variable, we propose to augment the training pairs, \\(\\{(\\mathbf{x}^{(m)}, \\mathbf{\\bar{y}}^{(m)})\\}_{m=1}^M\\), where the \\(\\mathbf{\\bar{y}}^{(m)}\\) with the \\(\\mathbf{\\bar{y}}^{(m)\\)’s computed with one single initial migration-velocity model, \\(\\mathbf{x}_0\\), with \\(\\mathbf{\\bar{y}}^{(m)\\) obtained with different (perturbed) initial migration-velocity model, \\(\\mathbf{x}_0\\). The aim of this training dataset augmentation is to improve the robustness of WISE—i.e., make its neural posterior estimation less dependent on the choice for the initial migration-velocity model, \\(\\mathbf{x}_0\\).\nResults: To improve the neural posterior estimation’s robustness, multiple initial migration-velocity models, \\(\\mathbf{x}_0\\), are obtained by perturbing the ground-truth velocity models, \\(\\mathbf{x}\\), followed by extensive smoothing. For comparison, we train the baseline CNF on \\(M=800\\) velocity-extended image pairs, fir a single \\(\\mathbf{x}_0\\). This baseline is compared with XXX explain use text below….\nUtilizing 2D slices of the compass dataset (E. Jones et al. 2012), we generate velocity-RTM training pairs through the aforementioned approach. The dataset is divided, allocating \\(800\\) pairs for training and \\(150\\) for testing. By perturbing the velocity models an additional one to three times, we augment the velocity-RTM training dataset to \\(1600\\), \\(2400\\), and \\(3200\\) pairs, respectively. Conversely, we replicate the baseline dataset two to four times to match the augmented dataset sizes. The CNFs trained with these varied datasets are evaluated by structural similarity index measure (SSIM) and root mean square error (RMSE) against the ground truth. The results show that posterior samples progressively align more closely with the ground truth and reduce uncertainty as the dataset augmentation size increases. Furthermore, they also demonstrate that the augmented datasets consistently outperform their repetitive counterparts.\nNovelty The success of our approach is rooted in the innovative reinterpretation of the imaging background model as a stochastic latent variable, which we resample during training. This strategy serves two pivotal functions: firstly, it significantly enhances the robustness of our inference results wrt the background model at test time, ensuring reliability in diverse scenarios. Secondly, by capturing the variabilities from perturbing and smoothing velocity as new migration background models, we not only broaden the scope of our model’s applicability but also directly contribute to the improved precision and decreased uncertainty of our posterior estimates."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "These abstracts are released under the Creative Commons License type CC BY. 2024 Copyrights (c) SLIM Group, Georgia Institute of Technology.\nAll codes used to produce these results are released under MIT license."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Image2024",
    "section": "",
    "text": "This is a Quarto website.\nAll submissions to the Image23 conference with additional figures, references, …\nList of abstrac:\n\nDigital twin with control An uncertainty-aware digital twin for geological carbon storage"
  },
  {
    "objectID": "DigitalTwin/abstract.html",
    "href": "DigitalTwin/abstract.html",
    "title": "Digital Twin",
    "section": "",
    "text": "\\[\n    \\newcommand{\\pluseq}{\\mathrel{+}=}\n\\]"
  },
  {
    "objectID": "DigitalTwin/abstract.html#objectives-and-scope",
    "href": "DigitalTwin/abstract.html#objectives-and-scope",
    "title": "Digital Twin",
    "section": "Objectives and scope",
    "text": "Objectives and scope\nWrite objective and scope"
  },
  {
    "objectID": "DigitalTwin/abstract.html#method",
    "href": "DigitalTwin/abstract.html#method",
    "title": "Digital Twin",
    "section": "Method",
    "text": "Method\nWrite methods here"
  },
  {
    "objectID": "DigitalTwin/abstract.html#results",
    "href": "DigitalTwin/abstract.html#results",
    "title": "Digital Twin",
    "section": "Results",
    "text": "Results\nWrite results here\n\n\n\nFigure 1: Caption 1\n\n\n\n\n\nFigure 2: Caption 2"
  },
  {
    "objectID": "DigitalTwin/abstract.html#significance",
    "href": "DigitalTwin/abstract.html#significance",
    "title": "Digital Twin",
    "section": "Significance",
    "text": "Significance\nWrite significance. Additional material is available at https://slimgroup.github.io/IMAGE2024/."
  },
  {
    "objectID": "DigitalTwin/abstract.html#introduction",
    "href": "DigitalTwin/abstract.html#introduction",
    "title": "Digital Twin",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "DigitalTwin/abstract.html#methodology",
    "href": "DigitalTwin/abstract.html#methodology",
    "title": "Digital Twin",
    "section": "Methodology",
    "text": "Methodology"
  },
  {
    "objectID": "DigitalTwin/abstract.html#synthetic-case-studies",
    "href": "DigitalTwin/abstract.html#synthetic-case-studies",
    "title": "Digital Twin",
    "section": "Synthetic case studies",
    "text": "Synthetic case studies"
  },
  {
    "objectID": "DigitalTwin/abstract.html#discussion-and-conclusions",
    "href": "DigitalTwin/abstract.html#discussion-and-conclusions",
    "title": "Digital Twin",
    "section": "Discussion and conclusions",
    "text": "Discussion and conclusions\n\nReferences"
  },
  {
    "objectID": "DigitalTwin/abstract.html#acknowledgement",
    "href": "DigitalTwin/abstract.html#acknowledgement",
    "title": "Digital Twin",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\nThis research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center."
  },
  {
    "objectID": "DigitalTwin/abstract.html#software-availability",
    "href": "DigitalTwin/abstract.html#software-availability",
    "title": "Digital Twin",
    "section": "Software availability",
    "text": "Software availability"
  }
]